{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Sprawdzenie kernela \n\nNa pocz\u0105tek sprawd\u017a czy silnik wykonawczy Twojego notatnika to PySpark. \nM\u00f3g\u0142by on by\u0107 po prostu interpreterem Pythona, jednak w\u00f3wczas zmienne kontekstu musieliby\u015bmy tworzy\u0107 samodzielnie.\n\nSprawd\u017a, czy obiekt kontekstu jest dost\u0119pny. W przypadku *Spark SQL* jest to `SparkSession`"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "spark"}, {"cell_type": "markdown", "metadata": {}, "source": "Dzi\u0119ki powy\u017cszej informacji dowiedzieli\u015bmy si\u0119 nie tylko w jakim trybie zosta\u0142 uruchomiony Spark obs\u0142uguj\u0105cy nasze polecenia, w jakiej jest wersji, ale tak\u017ce czy obs\u0142uguje funkcjonalno\u015b\u0107 platformy Hive.\n\nDowiedz si\u0119 tak\u017ce pod jakim u\u017cytkownikiem dzia\u0142amy w ramach tego notatnika."}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%sh \nwhoami"}, {"cell_type": "markdown", "metadata": {}, "source": "Czas na nasze w\u0142a\u015bciwe zadania. \n\nW razie potrzeby korzystaj z https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html\n\n# 20 Years of Games"}, {"cell_type": "markdown", "metadata": {}, "source": "**7. Zaczytaj do zmiennej gameInfosDF zawarto\u015b\u0107 pliku ign.csv**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "username = \"jankiewicz_krzysztof\" # UWAGA! ustaw zmienn\u0105 username na poprawn\u0105 warto\u015b\u0107\n\ngameInfosDF=spark.read.\\\n    option(\"inferSchema\", \"true\").\\\n    csv(f\"/user/{username}/ign.csv\", header=True).cache()"}, {"cell_type": "markdown", "metadata": {}, "source": "**8. Wy\u015bwietl schemat zmiennej gameInfosDF**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "gameInfosDF.printSchema()"}, {"cell_type": "markdown", "metadata": {"autoscroll": "auto"}, "source": "Mo\u017cesz tak\u017ce po prostu przygl\u0105dn\u0105\u0107 si\u0119 jej kolumnom"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "gameInfosDF.columns"}, {"cell_type": "markdown", "metadata": {"autoscroll": "auto"}, "source": "Zobaczmy te\u017c trzy pierwsze wiersze. Zr\u00f3bmy to na kilka sposob\u00f3w. \n\n* Na pocz\u0105tek metoda `show()`"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "gameInfosDF.limit(3).show()"}, {"cell_type": "markdown", "metadata": {"autoscroll": "auto"}, "source": "Przetwarzane dane mog\u0105 by\u0107 du\u017ce. Wyniki natomiast z regu\u0142y s\u0105 znacznie mniejsze, to pozwala nam je (o ile znamy ich wielko\u015b\u0107) przekonwertowa\u0107 do obiekt\u00f3w `pandas DataFrame` i dzi\u0119ki temu przedstawi\u0107 w przyja\u017aniejszej postaci.\n* metoda `toPandas()`"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "gameInfosDF.limit(3).toPandas()"}, {"cell_type": "markdown", "metadata": {"autoscroll": "auto"}, "source": "Za pomoc\u0105 parametru konfiguracyjnego `spark.sql.repl.eagerEval.enabled` naszego kontekstu, r\u00f3wnie\u017c mo\u017cemy \nu\u0142atwi\u0107 sobie wgl\u0105d w zawarto\u015b\u0107 naszych wynik\u00f3w. Warto tak\u017ce ustawi\u0107 parametr aby kontrolowa\u0107 liczb\u0119 pobieranych w ten spos\u00f3b wierszy (tak, w razie niedoszacowania wyniku)\n* parametr `spark.sql.repl.eagerEval.enabled`"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\nspark.conf.set('spark.sql.repl.eagerEval.maxNumRows', 3)\ngameInfosDF"}, {"cell_type": "markdown", "metadata": {"autoscroll": "auto"}, "source": "Wykorzystuj powy\u017csze, aby m\u00f3c podgl\u0105da\u0107 uzyskiwane wyniki"}, {"cell_type": "markdown", "metadata": {}, "source": " \n**9. Na pocz\u0105tek co\u015b prostego. \nWy\u015bwietl trzy najlepiej ocenione gry wydane w roku 2016 na platform\u0119 PC.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.sql.functions import col, lit\n# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "**10. Okre\u015bl dla ka\u017cdej oceny opisowej (score_phrase) minimaln\u0105 i \nmaksymaln\u0105 ocen\u0119 liczbow\u0105. Wyniki posortuj\nrosn\u0105co pod wzgl\u0119dem minimalnej oceny liczbowej.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.sql.functions import *\nspark.conf.set('spark.sql.repl.eagerEval.maxNumRows', 20)\n# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "**11. To mo\u017ce co\u015b trudniejszego. Wyznacz liczb\u0119 oraz \u015bredni\u0105 ocen\u0119 gier wydawanych w poszczeg\u00f3lnych latach\npocz\u0105wszy od roku 2000 na poszczeg\u00f3lne platformy. Nie analizuj wszystkich platform \u2013 ogranicz je tylko do\ntych, dla kt\u00f3rych liczba wszystkich recenzji gier bior\u0105c pod uwag\u0119 wszystkie lata przekroczy\u0142a 500.**\n\n*Uwaga: Klasycznie odwo\u0142aliby\u015bmy si\u0119 do \u017ar\u00f3d\u0142owego zboru danych dwa razy. Raz aby wyznaczy\u0107 popularne platformy, a nast\u0119pnie aby wyznaczy\u0107 ostateczny wynik. \nKorzystaj\u0105c z funkcji analitycznych mo\u017cesz to zadanie rozwi\u0105za\u0107 si\u0119gaj\u0105c do \u017ar\u00f3d\u0142owych danych tylko raz.*\n\n**Rozwi\u0105\u017c to zadanie na dwa sposoby:**\n\na. Za pomoc\u0105 DataFrame API\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.sql.window import Window\n# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "b. Za pomoc\u0105 SQL (po zarejestrowaniu \u017ar\u00f3de\u0142 danych jako tymczasowych perspektyw)."}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "gameInfosDF.createOrReplaceTempView(\"gameinfos\")\n# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "**12. Je\u015bli masz swoj\u0105 ulubion\u0105 seri\u0119 gier (https://pl.wikipedia.org/wiki/Kategoria:Serie_gier_komputerowych)\nzobacz jakie \u015brednie oceny zdoby\u0142y poszczeg\u00f3lne pozycje z tej serii. Wyniki posortuj chronologicznie.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "**13. (opcjonalne) Por\u00f3wnaj ze sob\u0105 gry wchodz\u0105ce w sk\u0142ad wybranych serii gier wchodz\u0105cych w sk\u0142ad 20\nnajlepszych serii wg Guinessa (lista z 2010 roku). W zwi\u0105zku z tym, \u017ce gry nie s\u0105 wydawane co roku, pogrupuj\ndane w przedzia\u0142y o d\u0142ugo\u015bci 5 lat.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# brudnopis"}, {"cell_type": "markdown", "metadata": {}, "source": " \n# MondialDB \u2013 DataFrames"}, {"cell_type": "markdown", "metadata": {}, "source": "**14. Na pocz\u0105tku do zmiennych `citiesDF`, `countriesDF` za\u0142aduj odpowiednio dane z plik\u00f3w\n`mondial.cities.json`, `mondial.countries.json`**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "citiesDF = spark.read.json(f\"/user/{username}/mondial.cities.json\").cache()\ncountriesDF = spark.read.json(f\"/user/{username}/mondial.countries.json\").cache()"}, {"cell_type": "markdown", "metadata": {}, "source": "**15. Zapoznaj si\u0119 z ich struktur\u0105. Zwr\u00f3\u0107 uwag\u0119 na wyst\u0119puj\u0105ce typy array.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "citiesDF.printSchema()\ncountriesDF.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "**16. Zanim zaczniesz realizowa\u0107 zadania, zapoznaj si\u0119 ze funkcj\u0105 `explode`, kt\u00f3ra nadaje si\u0119 \u015bwietnie do pracy z tablicami i ich rozp\u0142aszczania.**\n\n**Przyk\u0142adowe zapytanie:**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "countriesDF.where(\"name = 'Poland'\").\\\n            select(col(\"name\"), explode(col(\"population\")).alias(\"pop_in_years\"))"}, {"cell_type": "markdown", "metadata": {}, "source": "Zwr\u00f3\u0107 uwag\u0119 tak\u017ce na inne funkcje z tej rodziny jak: `explode_outer`, `posexplode`, `posexplode_outer`\nhttps://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html\n\n\nWszystkie zadania wykonaj korzystaj\u0105c *DataFrame API*. Nie korzystaj z SQL."}, {"cell_type": "markdown", "metadata": {}, "source": "**17. Oblicz sum\u0119 ludno\u015bci wszystkich Pa\u0144stw na rok 2010. \nW sytuacji gdy w danym kraju nie przeprowadzono\nbadania w roku 2010 wykorzystaj najnowsze z bada\u0144 wcze\u015bniejszych.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.sql.window import Window\n# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "**18. By\u0142o ci\u0119\u017cko? Nie wierz\u0119.**\n\n**Teraz ju\u017c b\u0119dzie z g\u00f3rki. Podaj nazwy i g\u0119sto\u015b\u0107 zaludnienia trzech kraj\u00f3w o najwi\u0119kszej g\u0119sto\u015bci zaludnienia w roku 2010.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n**19. Podaj trzy kraje o najwi\u0119kszym procencie ludno\u015bci \u017cyj\u0105cym w miastach powy\u017cej 50 000 mieszka\u0144c\u00f3w w roku\n2010.**"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# tu wprowad\u017a swoje rozwiazanie\n"}, {"cell_type": "markdown", "metadata": {}, "source": "No c\u00f3\u017c, dane dotycz\u0105ce ludno\u015bci w miastach s\u0105 zapewne nowsze ni\u017c z 2010 roku.\nNa marginesie, zar\u00f3wno Melilla jak i Ceuta to hiszpa\u0144skie miasta, afryka\u0144skie eksklawy po\u0142o\u017cone na terytorium\nMaroka. Oba licz\u0105 ponad 70 ty\u015b mieszka\u0144c\u00f3w i oba posiadaj\u0105 autonomi\u0119 (uzyskan\u0105 jednocze\u015bnie w marcu 1995 roku)\ndlatego znalaz\u0142y si\u0119 w naszym zestawieniu.\nA co to takiego eksklawy i czy enklawa jest tym samym, to ju\u017c mo\u017cesz przeczyta\u0107 samodzielnie np. tu:\nhttps://pl.wikipedia.org/wiki/Eksklawa"}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# brudnopis"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}, "name": "Spark \u2013 DataFrames"}, "nbformat": 4, "nbformat_minor": 4}